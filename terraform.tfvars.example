# Proxmox Configuration
proxmox_host           = "proxmox.example.com"  # Hostname or IP address of Proxmox host
proxmox_port           = 8006                   # API port (default: 8006)
proxmox_tls            = true                   # Use HTTPS (true) or HTTP (false)
proxmox_username       = "root@pam"
proxmox_password       = "your-password-here"
proxmox_insecure       = true                   # Set to false if using valid TLS certificates
proxmox_node_name      = "pve"
proxmox_disk_datastore = "local-lvm"            # Datastore for VM disks
proxmox_iso_datastore  = "local"                # Datastore for ISO/image downloads
proxmox_network_bridge = "vmbr0"
# proxmox_vlan_tag       = 100          # Optional: Set a global VLAN tag for all VMs (uncomment to use)

# Network Configuration
network_gateway = "10.0.20.1"
# nameservers     = ["1.1.1.1", "1.0.0.1"]  # Optional: Override default nameservers
starting_ip     = "10.0.20.11"  # First node gets this IP, then increments sequentially
starting_vm_id  = 1000          # First node gets this VM ID, then increments sequentially

# Cluster Configuration
cluster_name     = "talos"
cluster_endpoint = "https://10.0.20.10:6443" # VIP shared across control plane nodes (should be 1 IP before starting_ip)
talos_version    = "v1.11.5"

# Talos Image Extensions
# Add system extensions to include in the Talos image
# See available extensions at: https://factory.talos.dev/
talos_image_extensions = [
  "siderolabs/qemu-guest-agent",
  # "siderolabs/iscsi-tools",
  # "siderolabs/util-linux-tools",
  # "siderolabs/intel-ucode",
  # "siderolabs/amd-ucode",
]

# Node Pool Configuration
# Define your cluster topology here!
# IPs and VM IDs are assigned sequentially starting from starting_ip and starting_vm_id
#
# Example with these settings (cluster_endpoint=10.0.20.10, starting_ip="10.0.20.11", starting_vm_id=1000):
#   - VIP (control plane shared):  10.0.20.10 (cluster_endpoint, not assigned to any single node)
#   - controlplane (3 nodes): IPs .11-.13, VM IDs 1000-1002
#   - workers_amd64 (2 nodes): IPs .14-.15, VM IDs 1003-1004
#   - workers_arm64 (if enabled): IPs .16+, VM IDs 1005+
#
# IMPORTANT: Keep cluster_endpoint IP separate from node IPs to avoid conflicts!
#
# Optional per-pool VLAN tag override example:
#   vlan_tag = 200  # Add this to any node pool to override global VLAN setting
node_pools = {
  # Control plane nodes (always needed, minimum 1, recommended 3 for HA)
  controlplane = {
    node_type    = "controlplane"
    architecture = "amd64"
    count        = 3
    cpu_cores    = 2
    memory_mb    = 2048
    disk_size_gb = 10
  }

  # amd64 worker nodes
  workers_amd64 = {
    node_type    = "worker"
    architecture = "amd64"
    count        = 2
    cpu_cores    = 1
    memory_mb    = 1024
    disk_size_gb = 10
  }

  # arm64 worker nodes (optional)
  workers_arm64 = {
    node_type    = "worker"
    architecture = "arm64"
    count        = 0        # Set to desired number or 0 to disable
    cpu_cores    = 1
    memory_mb    = 1024
    disk_size_gb = 10
  }
}
